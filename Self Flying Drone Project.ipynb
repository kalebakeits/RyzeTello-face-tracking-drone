{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Self Flying Drone Using Ryze Tello Drone\n",
    "A Ryze Tello Drone is required for this part of the project.\n",
    "\n",
    "## Objectives:\n",
    "\n",
    "- Return bounding box around face\n",
    "- Classify face as mine or not\n",
    "- Calculate velocities required to track face\n",
    "- Send RC controls to the drone [velocities].\n",
    " \n",
    "    \n",
    "## Improvements:\n",
    "\n",
    "Improvements made on the original project by Jabrills: https://www.youtube.com/watch?v=esw88_gKOpA\n",
    "\n",
    "- Auto-land if no face is detected for certain duration of time\n",
    "- Search for the face to track by panning and moving up and down\n",
    "- Implement a fail safe key\n",
    "- Implement face recognition to ignore unwanted faces. Useful when used around other people\n",
    "\n",
    "    \n",
    "##### Comments:\n",
    "\n",
    "- Initially tried to convert pixel values to centimeters which was unecessary and only accurate in the z-axis between 30cm and 150cm\n",
    "- Thought the face recognition model would be too slow however it performs fast enough\n",
    "- Used a counter instead of time.time()-kill to determine how long it had been since the last face was detected\n",
    "      \n",
    "## Instructions:\n",
    "\n",
    "*** If you have not set up the facial recognition please do before performing these steps. This can be done using the file \"Create Training Data and Train Model.ipynb\". The file contains the relevant setup instructions.***\n",
    "    \n",
    "1. Start with the Drone Wi-Fi Disconnected (It causes issues when trying to import modules if it's connected)\n",
    "2. Import the modules\n",
    "    2.1 (Importing djitellopy before connecting to the drone wifi causes the program to freeze)\n",
    "3. Connect to the drone Wi-Fi\n",
    "4. Place the drone on a flat surface that is the same level as your feet.\n",
    "5. Run all the code up to and including the flight loop\n",
    "6. To land, spam the Esc key\n",
    "    - If the landing zone is not safe for landing. Place your hand under the drone\n",
    "    - If the drone crash lands; it may be necessary to restart the kernel and reset the drone.\n",
    "    - If the drone lands succesfully; to take off again, simply run the flight loop.\n",
    "    - Resetting the drone and restarting the kernel should fix all connectivity issues\n",
    "    \n",
    "#### Remarks\n",
    "\n",
    "not_face_detected() is not finished yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables that control drone and program behviour\n",
    "\n",
    "#### Video Stream\n",
    "\n",
    "- Scale Factor: Adjust the video stream size without affecting the movement calculations and grid placement\n",
    "- FPS: How many times the drone sends a captured frame every second \n",
    "- Show Stream: True or False\n",
    "    \n",
    "#### Movement \n",
    "\n",
    "- Green Zone: Region in which recentering is not required   \n",
    "- Z Zero: The 0 point on the z-axis. When z is equal to this value, the drone holds it's position. \n",
    "- Z Forward: Closest that drone can be to face\n",
    "- Z Backward: Furthest drone can be from the face    \n",
    "- Up-down(Not detected): Velocity of up and down movemnt to search for face.\n",
    "    \n",
    "#### Display\n",
    "\n",
    "- Display Info: Text and grid information displayed on video feed\n",
    "- Width: Width of the video stream\n",
    "- Height: Height of the video stream\n",
    "- Resolution: This is adjusted using the width and height\n",
    "- Center: The center of the video stream, used to calculate movement required to recenter face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from djitellopy import Tello\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tello = Tello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video and Display\n",
    "scale_factor = 1 # This is the inverse scale so scale_factor = 1/scale\n",
    "width = int(960/scale_factor)\n",
    "height = int(720/scale_factor)\n",
    "resolution = (width,height)\n",
    "center = (int(resolution[0]/2),int(resolution[1]/2))\n",
    "FPS = 24\n",
    "show_stream = False\n",
    "\n",
    "#Movement\n",
    "green_zone = 150/scale_factor\n",
    "z_zero = 125\n",
    "z_forward = 110/scale_factor\n",
    "z_backward = 140/scale_factor\n",
    "not_detected_up_down_velocity = 15\n",
    "\n",
    "#Face Detection and Recognition\n",
    "model = tf.keras.models.load_model(\"Face-Recognition.model\")\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "#Dipsplay info on video caputre e.g grid lines\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "top_text = (50,50)\n",
    "y_info = (50,100)\n",
    "x_info = (50,150)\n",
    "z_info = (50,200)\n",
    "bat_info = (50,250)\n",
    "bottom_text = (50, 715)\n",
    "text_colour = (0,255,255)\n",
    "face_box_colour = (255,255,255)\n",
    "error_box_colour = (0,255,0)\n",
    "grid_colour = (0,255,255)\n",
    "grid_colour_2 = (0,255,0)\n",
    "grid_thickness = 3\n",
    "default_thickness = 10\n",
    "y_min = int(resolution[1]/2-green_zone/2)\n",
    "y_max = int(resolution[1]/2+green_zone/2)\n",
    "x_min = int(resolution[0]/2-green_zone/2)\n",
    "x_max = int(resolution[0]/2+green_zone/2)\n",
    "line_1_start = (0,y_min)\n",
    "line_1_end = (resolution[0],y_min)\n",
    "line_2_start = (0,y_max)\n",
    "line_2_end = (resolution[0],y_max)\n",
    "line_3_start = (x_min,0)\n",
    "line_3_end = (x_min,resolution[1])\n",
    "line_4_start = (x_max,0)\n",
    "line_4_end = (x_max,resolution[1])\n",
    "\n",
    "#Define these variables first to prevent cv2 image caputre giving an error\n",
    "#This is becuase image caputre is empty in the beginning as the drone doesn't return an initial image fast enough\n",
    "x_mid = width/2\n",
    "y_mid = height/2\n",
    "face = 1\n",
    "w,h = 1,1\n",
    "count = 0\n",
    "face_detected = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_right(x):\n",
    "    \n",
    "    \"\"\" \n",
    "    Returns left right or hold\n",
    "    Determines x-axis direction for the drone\n",
    "    \"\"\"\n",
    "    if x >= x_min and x <= x_max: return 'hold'\n",
    "    elif x < x_min: return 'left'\n",
    "    elif x > x_max: return 'right'\n",
    "    \n",
    "\n",
    "def up_down(y):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns Up down or hold\n",
    "    Determines y-axis direction for the drone\n",
    "    \"\"\"\n",
    "    if y >= y_min and y <= y_max: return 'hold'\n",
    "    elif y < y_min: return 'up'\n",
    "    elif y > y_max: return 'down'\n",
    "    \n",
    "def forward_back(z):\n",
    "    \n",
    "    \"\"\" \n",
    "    Returns forward, back or hold\n",
    "    Determines z-axis movement for the drone\n",
    "    \"\"\"\n",
    "    if z <= z_forward and z >= z_backward: return 'hold'\n",
    "    elif z < z_forward: return 'forward'\n",
    "    elif z > z_backward: return 'back'\n",
    "    \n",
    "def convert_z(z):\n",
    "    \n",
    "    \"\"\" \n",
    "    Corrects the z-axis by inverting it\n",
    "    \"\"\"\n",
    "    z = -z+125\n",
    "    return(z)\n",
    "\n",
    "def grid():\n",
    "    \n",
    "    \"\"\"\n",
    "    All the relevant information that is displayed on screen\n",
    "    \"\"\"\n",
    "    cv2.line(img,line_1_start,line_1_end,grid_colour,grid_thickness)\n",
    "    cv2.line(img,line_2_start, line_2_end,grid_colour,grid_thickness)\n",
    "    cv2.line(img,line_3_start,line_3_end,grid_colour,grid_thickness)\n",
    "    cv2.line(img,line_4_start,line_4_end,grid_colour,grid_thickness)\n",
    "    cv2.circle(img, (int(resolution[0]/2),int(resolution[1]/2)), default_thickness,grid_colour)\n",
    "    up = up_down(y_mid)\n",
    "    right = left_right(x_mid)\n",
    "    forward = forward_back(h)\n",
    "    cv2.putText(img,\"Right %s\" %(right),x_info,font, 1,text_colour,2,cv2.LINE_4)\n",
    "    cv2.putText(img,\"Up %s\"%(up),y_info,font, 1,text_colour,2,cv2.LINE_4)\n",
    "    cv2.putText(img,\"Forward %s\"%(forward),z_info,font, 1,text_colour,2,cv2.LINE_4)\n",
    "    cv2.circle(img, center, default_thickness ,grid_colour)\n",
    "    \n",
    "def xyz_movement(x,y,z):\n",
    "    \n",
    "    \"\"\"\n",
    "        Compare x, y and z values of the face with the center and sends controls.\n",
    "        Controls forced within the range of -100 and 100 to the Drone. \n",
    "    \"\"\"\n",
    "    x_1 = x\n",
    "    y_1 = y\n",
    "    x = x - width/2\n",
    "    y = y - height/2\n",
    "    \n",
    "    x = int((x*75)/(width/2))\n",
    "    y = int((-y*75)/(height/2))\n",
    "    \n",
    "    if left_right(x_1) == \"hold\":\n",
    "        x = 0\n",
    "    if up_down(y_1) == \"hold\":\n",
    "        y = 0\n",
    "    if forward_back == \"hold\":\n",
    "        z = z_zero\n",
    "\n",
    "    z = convert_z(z)\n",
    "    z = int((z*75)/200)\n",
    "    tello.send_rc_control(0,z,y,x)\n",
    "    \n",
    "def not_face_detected():\n",
    "    \"\"\"\n",
    "    Incomplete\n",
    "    Used to locate the face if it is not detected.\n",
    "    \"\"\"\n",
    "    not_detected_up_down_velocity = - not_detected_up_down_velocity\n",
    "    tello.send_rc_control(0,0,not_detected_up_down_velocity,50)\n",
    "    \n",
    "def prepare(image):\n",
    "    \"\"\"\n",
    "    Prepare image (current frame) to fit the model.\n",
    "    \"\"\"\n",
    "    IMG_SIZE = 100\n",
    "    new_array = cv2.resize(image, (IMG_SIZE,IMG_SIZE))/255.0\n",
    "    return     np.array(new_array).reshape(-1,IMG_SIZE,IMG_SIZE,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'io' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9b86936f38b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mHover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \"\"\"\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtext_trap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_trap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtello\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'io' is not defined"
     ]
    }
   ],
   "source": [
    "#Suppress the program from printing every single command that it sends\n",
    "text_trap = io.StringIO()\n",
    "sys.stdout = text_trap\n",
    "#Connect to the drone and takeoff\n",
    "tello.connect()\n",
    "time.sleep(2)\n",
    "tello.streamoff()\n",
    "tello.streamon()\n",
    "tello.takeoff()\n",
    "time.sleep(5)\n",
    "tello.send_rc_control(0,0,75,0)\n",
    "time.sleep(2)\n",
    "tello.send_rc_control(0,0,0,0)\n",
    "kill = time.time()\n",
    "\n",
    "\n",
    "\n",
    "#Start detecting the face and tracking it\n",
    "while True:\n",
    "    \n",
    "    #Get frame from drone and detect face\n",
    "    frame_read = tello.get_frame_read()\n",
    "    myFrame = frame_read.frame\n",
    "    img = cv2.resize(myFrame, (width,height))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    \n",
    "    #Model Prediction\n",
    "    for (x,y,w,h) in faces:\n",
    "        prediction = model.predict(prepare(gray[y:y+h, x:x+w]))\n",
    "        if prediction[0][0] < 0.1:\n",
    "            face_detected = True\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h),face_box_colour , 2)\n",
    "            x_mid = (2*x + w)/2\n",
    "            y_mid = (2*y + h)/2\n",
    "    \n",
    "    if show_stream:\n",
    "        #For Better performance, set show_stream = False when not testing\n",
    "        grid()\n",
    "        cv2.imshow(\"Img\", img)\n",
    "        cv2.waitKey(300)\n",
    "     \n",
    "    if face_detected:\n",
    "        #Move the drone (or hold position)\n",
    "        xyz_movement(x_mid,y_mid,h)\n",
    "        time.sleep(1/FPS)\n",
    "        kill = time.time()\n",
    "        \n",
    "    elif not face_detected:\n",
    "        #Tell the Drone to stop moving\n",
    "        tello.send_rc_control(0,0,0,0)\n",
    "        if time.time() - kill > 15:\n",
    "            tello.land()\n",
    "            break\n",
    "            \n",
    "    c = cv2.waitKey(7) % 0x100\n",
    "    if c == 27 or c == 10:\n",
    "        tello.land()\n",
    "        break\n",
    "    #Reset Face Detected\n",
    "    face_detected = False \n",
    "\n",
    "\n",
    "tello.end()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "sys.stdout = sys.__stdout__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
